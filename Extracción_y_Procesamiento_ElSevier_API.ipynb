{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e17739be-79dc-495f-9740-f913564e2f98",
      "metadata": {
        "id": "e17739be-79dc-495f-9740-f913564e2f98"
      },
      "source": [
        "# Extracción y Procesamiento de Información sobre Artículos científicos en ElSevier\n",
        "\n",
        "Programa de extracción de artículos científicos publicados en ElSevier a través de la API oficial publicada por esta editorial"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "427f8674-f4bd-4bff-a3ff-cf16fffc9520",
      "metadata": {
        "id": "427f8674-f4bd-4bff-a3ff-cf16fffc9520"
      },
      "source": [
        "## Instalación de librerías para el consumo y procesamiento de la información\n",
        "\n",
        "1. ELSevier API: Se usa el API publicado en https://github.com/ElsevierDev/elsapy que permite la extracción de la información de los artículos publicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "273facad-97bd-43b4-a7e8-16bcbca19cf3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "273facad-97bd-43b4-a7e8-16bcbca19cf3",
        "outputId": "e8305681-3430-4733-d1a7-8ea43ae93bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting elsapy\n",
            "  Downloading elsapy-0.5.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from elsapy) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->elsapy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->elsapy) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->elsapy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->elsapy) (2.10)\n",
            "Installing collected packages: elsapy\n",
            "Successfully installed elsapy-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install elsapy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Pandas: Permite la manupulación de conjuntos de datos en memoria para un procesamiento más rápido y versátil\n",
        "\n"
      ],
      "metadata": {
        "id": "wLTsKza0tIA6"
      },
      "id": "wLTsKza0tIA6"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVKafh2OsiGo",
        "outputId": "8b4ad700-43a1-4648-9fda-97e53c8e7878"
      },
      "id": "OVKafh2OsiGo",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Beautiful Soap: Librería usada para tareas de procesamiento de contenido web o Web Scrapping de información semi-estructurada en contenido con formato html/xml  "
      ],
      "metadata": {
        "id": "9qITXJKsuBOQ"
      },
      "id": "9qITXJKsuBOQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed819a16-e57f-4e1f-8cd5-6847045fb33d",
      "metadata": {
        "id": "ed819a16-e57f-4e1f-8cd5-6847045fb33d",
        "outputId": "2126c996-eb5a-4541-f2e5-cb3c9982ce65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: soupsieve, beautifulsoup4\n",
            "Successfully installed beautifulsoup4-4.10.0 soupsieve-2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. URLLib versión 3: Permite establecer conexión y extraer el contenido de sitios web "
      ],
      "metadata": {
        "id": "xrFSQwCsuGKb"
      },
      "id": "xrFSQwCsuGKb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fde1edb0-2352-40fc-928f-7f15069ba2b8",
      "metadata": {
        "id": "fde1edb0-2352-40fc-928f-7f15069ba2b8",
        "outputId": "c978bf4e-0e1d-4cb5-fb8e-b779b9cc2e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: urllib3 in c:\\users\\denny\\anaconda3\\envs\\tf-gpu-lastest\\lib\\site-packages (1.26.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install urllib3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. LXML: Permite manipular contenido en formato XML de forma fácil"
      ],
      "metadata": {
        "id": "twYgebmnugUL"
      },
      "id": "twYgebmnugUL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cd66104-9bf9-4df4-890a-90ded3f5b37d",
      "metadata": {
        "id": "8cd66104-9bf9-4df4-890a-90ded3f5b37d",
        "outputId": "249493c6-db23-4fb2-8584-732a21458528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lxml\n",
            "  Downloading lxml-4.6.4-cp39-cp39-win_amd64.whl (3.5 MB)\n",
            "Installing collected packages: lxml\n",
            "Successfully installed lxml-4.6.4\n"
          ]
        }
      ],
      "source": [
        "!pip install lxml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. HTML5Lib: Librería que permite utilizar las propiedades de objetos HTML5 a fin de poder estructurar información en páginas web con este tipo de codificación"
      ],
      "metadata": {
        "id": "Av9O_lnWuphT"
      },
      "id": "Av9O_lnWuphT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "359134fc-d6f6-4faf-af25-f61c0a340c0e",
      "metadata": {
        "id": "359134fc-d6f6-4faf-af25-f61c0a340c0e",
        "outputId": "cae4f241-d536-4920-b5c2-643620387a22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting html5lib\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "Requirement already satisfied: six>=1.9 in c:\\users\\denny\\anaconda3\\envs\\tf-gpu-lastest\\lib\\site-packages (from html5lib) (1.15.0)\n",
            "Requirement already satisfied: webencodings in c:\\users\\denny\\anaconda3\\envs\\tf-gpu-lastest\\lib\\site-packages (from html5lib) (0.5.1)\n",
            "Installing collected packages: html5lib\n",
            "Successfully installed html5lib-1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install html5lib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Programa de extracción\n",
        "\n",
        "### Importación de las librerías a ser usadas"
      ],
      "metadata": {
        "id": "MZMKrICKvqzR"
      },
      "id": "MZMKrICKvqzR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7f26405-e109-421f-84e8-6f5561a4f032",
      "metadata": {
        "id": "e7f26405-e109-421f-84e8-6f5561a4f032"
      },
      "outputs": [],
      "source": [
        "from elsapy.elsclient import ElsClient\n",
        "from elsapy.elsprofile import ElsAuthor, ElsAffil\n",
        "from elsapy.elsdoc import FullDoc, AbsDoc\n",
        "from elsapy.elssearch import ElsSearch\n",
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "import copy\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga del archivo de configuración de seguridad para el llamado del API ElSevier"
      ],
      "metadata": {
        "id": "lGmXYaF4v6JQ"
      },
      "id": "lGmXYaF4v6JQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d129cd4-2a50-4ad5-a55f-d816feea5d6a",
      "metadata": {
        "id": "9d129cd4-2a50-4ad5-a55f-d816feea5d6a"
      },
      "outputs": [],
      "source": [
        "## Carga de archivo de configuración en formato json\n",
        "con_file = open(\"config.json\")\n",
        "config = json.load(con_file)\n",
        "con_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfbecb83-9302-417f-bc6e-5b71d1624311",
      "metadata": {
        "id": "cfbecb83-9302-417f-bc6e-5b71d1624311"
      },
      "outputs": [],
      "source": [
        "## Inicialización del objeto de conexión usando el valor de la API Key la cual se obtiene de registrándote en el site de desarrolladores: https://dev.elsevier.com/apikey/manage\n",
        "client = ElsClient(config['apikey'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definición de Función de Extracción Detallada de Información por Artículo Científico\n",
        "Extrae la información individual de cada artículo científico a partir del site  publicados en el indexador Scopus"
      ],
      "metadata": {
        "id": "Zf4Mw928wnGL"
      },
      "id": "Zf4Mw928wnGL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bff060a-8ecc-4554-aa1f-a53265df0b12",
      "metadata": {
        "id": "7bff060a-8ecc-4554-aa1f-a53265df0b12"
      },
      "outputs": [],
      "source": [
        "def get_scopus_info(id, URL, API_KEY):\n",
        "    resp = requests.get(URL,headers={'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
        "                                     'X-ELS-APIKey': config['apikey'],\n",
        "                                     'Cookie': '',\n",
        "                                     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:94.0) Gecko/20100101 Firefox/94.0'})\n",
        "    soup = BeautifulSoup(resp.text, 'lxml')\n",
        "    result = dict({\"id\": id})\n",
        "    if soup.find(id='abstractSection'):\n",
        "        result['abstract'] = soup.find(id='abstractSection').p.text\n",
        "    if soup.find(id='authorKeywords'):\n",
        "        keys = ''\n",
        "        for x in soup.find(id='authorKeywords').find_all('span'):\n",
        "            if keys != '':\n",
        "                keys += ','+x.text\n",
        "            else:\n",
        "                keys = x.text\n",
        "        result['keywords'] = keys\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracción de Información - Salud\n",
        "Se realiza un procesamiento de información sobre los artículos científicos relacionados al uso de Inteligencia Artificial en Políticas de Salud en América Latina.\n",
        "Para ello se usa el motor de búsqueda Scopus cuyos parámetros de búsqueda se encuentran documentados en https://dev.elsevier.com/sc_search_tips.html"
      ],
      "metadata": {
        "id": "YPiIfvxbxtUW"
      },
      "id": "YPiIfvxbxtUW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc957688-6252-47b4-9413-94a5421ff834",
      "metadata": {
        "id": "bc957688-6252-47b4-9413-94a5421ff834",
        "outputId": "6c2bab61-cbd4-4fe3-b37f-1c9ac126f49f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "doc_srch has 56 results.\n"
          ]
        }
      ],
      "source": [
        "## Búsqueda de artículos que cumplan con la mención de las siguientes palabras clave dentro del \"Título, Abstract y Términos Clave\":\n",
        "### (\"policy\" OR \"strategy\")\n",
        "### AND\n",
        "### (\"artificial intelligence\" OR \"machine learning\" OR \"NLP\" OR \"computer vision\")\n",
        "### AND\n",
        "### (\"latin america\" OR \"latinamerica\" OR \"Venezuela\" OR \"Colombia\" OR \"Peru\" OR \"Brazil\" OR \"Chile\" OR \"Argentina\" OR \"Uruguay\" OR \"Paraguay\")\n",
        "### AND\n",
        "### Áreas de: Salud(HEAL) OR Psicología(PSYC) OR Medicina(MEDI) OR Neurología(NEUR) OR Enfermería(NURS) OR Farmacia(PHAR) \n",
        "### Publicaciones a partir del 2011\n",
        "doc_srch = ElsSearch(\"(TITLE-ABS-KEY(policy) OR TITLE-ABS-KEY(strategy)) AND (TITLE-ABS-KEY(artificial intelligence) OR TITLE-ABS-KEY(machine learning) OR TITLE-ABS-KEY(NLP) OR TITLE-ABS-KEY(computer vision)) AND (TITLE-ABS-KEY(latin america) OR TITLE-ABS-KEY(latinamerica) OR TITLE-ABS-KEY(Venezuela) OR TITLE-ABS-KEY(Colombia) OR TITLE-ABS-KEY(Ecuador) OR TITLE-ABS-KEY(Peru) OR TITLE-ABS-KEY(Brazil) OR TITLE-ABS-KEY(Chile) OR TITLE-ABS-KEY(Argentina) OR TITLE-ABS-KEY(Uruguay) OR TITLE-ABS-KEY(Paraguay)) AND (SUBJAREA(HEAL) OR SUBJAREA(PSYC) OR SUBJAREA(MEDI) OR SUBJAREA(NEUR) OR SUBJAREA(NURS) OR SUBJAREA(PHAR)) AND PUBYEAR > 2010\",'scopus')\n",
        "doc_srch.execute(client, get_all = True)\n",
        "print (\"doc_srch has\", len(doc_srch.results), \"results.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2491938b-c88b-4470-abf1-a7c0de974332",
      "metadata": {
        "id": "2491938b-c88b-4470-abf1-a7c0de974332"
      },
      "outputs": [],
      "source": [
        "### Se almacena el resultado en formato CSV con los metadatos básicos de los artículos obtenidos (Ejecutado en el 8 de noviembre del 2021)\n",
        "### El detalle de los campos almacenados se encuentran en: https://dev.elsevier.com/documentation/ScopusSearchAPI.wadl\n",
        "doc_srch.results_df.to_csv('./data/elsevier_scopus_09.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a276137-25db-4136-90eb-412e58d02dcc",
      "metadata": {
        "id": "0a276137-25db-4136-90eb-412e58d02dcc"
      },
      "outputs": [],
      "source": [
        "### Por cada uno de los artículos obteneidos se enriquece la información a partir de la función desarrollada anteriormente\n",
        "df = pd.read_csv('./data/elsevier_scopus_09.csv')\n",
        "results_info_list = list()\n",
        "for i, row in df.iterrows():\n",
        "    results_info = get_scopus_info(row['dc:identifier'], json.loads(row['link'].replace(\"\\'\", \"\\\"\"))['scopus'], config['apikey'])\n",
        "    if results_info:\n",
        "        results_info_list.append(copy.deepcopy(results_info))\n",
        "\n",
        "df = pd.DataFrame(results_info_list)\n",
        "df.to_csv('./data/elsevier_scopus_09_detail_01.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8d6a7dc-d8af-493d-b4cb-bd10d5033ffe",
      "metadata": {
        "id": "b8d6a7dc-d8af-493d-b4cb-bd10d5033ffe"
      },
      "source": [
        "### Extracción de Información - Educación\n",
        "Se hace uso semejante pero enfocando el área de Educación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c89d21-11e1-4abf-bf2f-b70e3e32feb1",
      "metadata": {
        "id": "29c89d21-11e1-4abf-bf2f-b70e3e32feb1",
        "outputId": "b9cbd24c-e57b-49cb-d6f2-d38816eeaccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "doc_srch has 47 results.\n"
          ]
        }
      ],
      "source": [
        "## Búsqueda de artículos que cumplan con la mención de las siguientes palabras clave dentro del \"Título, Abstract y Términos Clave\":\n",
        "### (\"policy\" OR \"strategy\")\n",
        "### AND\n",
        "### (\"artificial intelligence\" OR \"machine learning\" OR \"NLP\" OR \"computer vision\")\n",
        "### AND\n",
        "### (\"latin america\" OR \"latinamerica\" OR \"Venezuela\" OR \"Colombia\" OR \"Peru\" OR \"Brazil\" OR \"Chile\" OR \"Argentina\" OR \"Uruguay\" OR \"Paraguay\")\n",
        "### AND\n",
        "### (\"education\" OR \"edu\" OR \"school\") -> ello debido a que en el API no se pudo identificar el uso del área de educación en específico\n",
        "### Publicaciones a partir del 2011\n",
        "doc_srch = ElsSearch(\"(TITLE-ABS-KEY(policy) OR TITLE-ABS-KEY(strategy)) AND (TITLE-ABS-KEY(artificial intelligence) OR TITLE-ABS-KEY(machine learning) OR TITLE-ABS-KEY(NLP) OR TITLE-ABS-KEY(computer vision)) AND (TITLE-ABS-KEY(latin america) OR TITLE-ABS-KEY(latinamerica) OR TITLE-ABS-KEY(Venezuela) OR TITLE-ABS-KEY(Colombia) OR TITLE-ABS-KEY(Ecuador) OR TITLE-ABS-KEY(Peru) OR TITLE-ABS-KEY(Brazil) OR TITLE-ABS-KEY(Chile) OR TITLE-ABS-KEY(Argentina) OR TITLE-ABS-KEY(Uruguay) OR TITLE-ABS-KEY(Paraguay)) AND (TITLE-ABS-KEY(education) OR TITLE-ABS-KEY(edu) OR TITLE-ABS-KEY(school)) AND PUBYEAR > 2010\",'scopus')\n",
        "doc_srch.execute(client, get_all = True)\n",
        "print (\"doc_srch has\", len(doc_srch.results), \"results.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce36627e-9121-4d4c-8bbf-30cdde8159d6",
      "metadata": {
        "id": "ce36627e-9121-4d4c-8bbf-30cdde8159d6"
      },
      "outputs": [],
      "source": [
        "### Se almacena el resultado en formato CSV con los metadatos básicos de los artículos obtenidos (Ejecutado en el 8 de noviembre del 2021)\n",
        "### El detalle de los campos almacenados se encuentran en: https://dev.elsevier.com/documentation/ScopusSearchAPI.wadl\n",
        "doc_srch.results_df.to_csv('./data/elsevier_scopus_10.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3bd226c-f86c-4a06-a1f7-e888a65a8474",
      "metadata": {
        "id": "b3bd226c-f86c-4a06-a1f7-e888a65a8474"
      },
      "outputs": [],
      "source": [
        "### Por cada uno de los artículos obteneidos se enriquece la información a partir de la función desarrollada anteriormente\n",
        "df = pd.read_csv('./data/elsevier_scopus_10.csv')\n",
        "results_info_list = list()\n",
        "for i, row in df.iterrows():\n",
        "    results_info = get_scopus_info(row['dc:identifier'], json.loads(row['link'].replace(\"\\'\", \"\\\"\"))['scopus'], config['apikey'])\n",
        "    if results_info:\n",
        "        results_info_list.append(copy.deepcopy(results_info))\n",
        "\n",
        "df = pd.DataFrame(results_info_list)\n",
        "df.to_csv('./data/elsevier_scopus_10_detail_01.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e6f5d88-e5ce-499d-b717-6108db21743d",
      "metadata": {
        "id": "7e6f5d88-e5ce-499d-b717-6108db21743d"
      },
      "source": [
        "### Extracción de Información - Agricultura\n",
        "Se hace uso semejante pero enfocando el área de Agricultura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948be187-924b-4ab3-859e-abb2d54700c3",
      "metadata": {
        "id": "948be187-924b-4ab3-859e-abb2d54700c3",
        "outputId": "17667512-728d-4492-f785-6f5a35b6f1f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "doc_srch has 39 results.\n"
          ]
        }
      ],
      "source": [
        "## Búsqueda de artículos que cumplan con la mención de las siguientes palabras clave dentro del \"Título, Abstract y Términos Clave\":\n",
        "### (\"policy\" OR \"strategy\")\n",
        "### AND\n",
        "### (\"artificial intelligence\" OR \"machine learning\" OR \"NLP\" OR \"computer vision\")\n",
        "### AND\n",
        "### (\"latin america\" OR \"latinamerica\" OR \"Venezuela\" OR \"Colombia\" OR \"Peru\" OR \"Brazil\" OR \"Chile\" OR \"Argentina\" OR \"Uruguay\" OR \"Paraguay\")\n",
        "### AND\n",
        "### Áreas de: Agricultura(AGRI) \n",
        "### Publicaciones a partir del 2011\n",
        "doc_srch = ElsSearch(\"(TITLE-ABS-KEY(policy) OR TITLE-ABS-KEY(strategy)) AND (TITLE-ABS-KEY(artificial intelligence) OR TITLE-ABS-KEY(machine learning) OR TITLE-ABS-KEY(NLP) OR TITLE-ABS-KEY(computer vision)) AND (TITLE-ABS-KEY(latin america) OR TITLE-ABS-KEY(latinamerica) OR TITLE-ABS-KEY(Venezuela) OR TITLE-ABS-KEY(Colombia) OR TITLE-ABS-KEY(Ecuador) OR TITLE-ABS-KEY(Peru) OR TITLE-ABS-KEY(Brazil) OR TITLE-ABS-KEY(Chile) OR TITLE-ABS-KEY(Argentina) OR TITLE-ABS-KEY(Uruguay) OR TITLE-ABS-KEY(Paraguay)) AND (SUBJAREA(AGRI)) AND PUBYEAR > 2010\",'scopus')\n",
        "doc_srch.execute(client, get_all = True)\n",
        "print (\"doc_srch has\", len(doc_srch.results), \"results.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f0f2b4e-7e1c-4c91-a722-8ad443789dbb",
      "metadata": {
        "id": "1f0f2b4e-7e1c-4c91-a722-8ad443789dbb"
      },
      "outputs": [],
      "source": [
        "### Se almacena el resultado en formato CSV con los metadatos básicos de los artículos obtenidos (Ejecutado en el 8 de noviembre del 2021)\n",
        "### El detalle de los campos almacenados se encuentran en: https://dev.elsevier.com/documentation/ScopusSearchAPI.wadl\n",
        "doc_srch.results_df.to_csv('./data/elsevier_scopus_11.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c68946-d11d-43bc-9244-b96b03cb58e6",
      "metadata": {
        "id": "c0c68946-d11d-43bc-9244-b96b03cb58e6"
      },
      "outputs": [],
      "source": [
        "### Por cada uno de los artículos obteneidos se enriquece la información a partir de la función desarrollada anteriormente\n",
        "df = pd.read_csv('./data/elsevier_scopus_11.csv')\n",
        "results_info_list = list()\n",
        "for i, row in df.iterrows():\n",
        "    results_info = get_scopus_info(row['dc:identifier'], json.loads(row['link'].replace(\"\\'\", \"\\\"\"))['scopus'], config['apikey'])\n",
        "    if results_info:\n",
        "        results_info_list.append(copy.deepcopy(results_info))\n",
        "\n",
        "df = pd.DataFrame(results_info_list)\n",
        "df.to_csv('./data/elsevier_scopus_11_detail_01.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estandarización para explotación de Información sobre Salud\n",
        "Se realiza un proceso de estandarización de la información para que pueda ser ingresada en un motor de base de datos relacional y de esta forma se permita su visualización en Superset"
      ],
      "metadata": {
        "id": "4-wNj8p6AQSL"
      },
      "id": "4-wNj8p6AQSL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importación de librerías para procesamiento"
      ],
      "metadata": {
        "id": "GJxcIEDbAni0"
      },
      "id": "GJxcIEDbAni0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5bd80a2-37d7-4da8-b9c4-93763c5849a3",
      "metadata": {
        "id": "d5bd80a2-37d7-4da8-b9c4-93763c5849a3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import ast"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga de la información sobre Salud"
      ],
      "metadata": {
        "id": "DBifHijkAxGd"
      },
      "id": "DBifHijkAxGd"
    },
    {
      "cell_type": "code",
      "source": [
        "df01 = pd.read_csv('./data/elsevier_scopus_09.csv')\n",
        "df02 = pd.read_csv('./data/elsevier_scopus_09_detail_01.csv')"
      ],
      "metadata": {
        "id": "MIC8dI23A8sr"
      },
      "id": "MIC8dI23A8sr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unificación de la metadata original y la información detallada extraída por Web Scrapping"
      ],
      "metadata": {
        "id": "Q64YR6VXA9ll"
      },
      "id": "Q64YR6VXA9ll"
    },
    {
      "cell_type": "code",
      "source": [
        "## Unificación de ambos datasets a partir de su identificador\n",
        "df01.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "df02.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "df02.rename(columns = {'id':'dc:identifier'}, inplace = True)\n",
        "df_total = pd.merge(df01,df02, on='dc:identifier')"
      ],
      "metadata": {
        "id": "xMyfruhFBIHZ"
      },
      "id": "xMyfruhFBIHZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Almacenamiento de la información unificada en formato csv\n",
        "df_total.to_csv('./data/elsevier_scopus_salud_total.csv', index=False)"
      ],
      "metadata": {
        "id": "WGSSELdGBffq"
      },
      "id": "WGSSELdGBffq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracción de la información semi-estructura de afiliaciones"
      ],
      "metadata": {
        "id": "VrMsvwn-BTSV"
      },
      "id": "VrMsvwn-BTSV"
    },
    {
      "cell_type": "code",
      "source": [
        "## Se extrae la información de las afiliaciones por cada uno de los artículos para estructurarlo en una tabla\n",
        "result_affiliation_list = list()\n",
        "for i,row in df_total.iterrows():\n",
        "    if row['affiliation']:\n",
        "        for affiliation_dict in ast.literal_eval(row['affiliation']):\n",
        "            result_affiliation_list.append({'dc:identifier':row['dc:identifier'],\n",
        "                                            'prism:coverDate': row['prism:coverDate'],\n",
        "                                           'affilname': affiliation_dict['affilname'],\n",
        "                                           'affiliation-city': affiliation_dict['affiliation-city'],\n",
        "                                           'affiliation-country': affiliation_dict['affiliation-country']})\n",
        "df_affiliation = pd.DataFrame(result_affiliation_list)"
      ],
      "metadata": {
        "id": "nd8sGApxBuEX"
      },
      "id": "nd8sGApxBuEX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Almacenamiento de la información de afiliaciones en formato csv\n",
        "df_affiliation.to_csv('./data/elsevier_scopus_salud_affiliation.csv', index=False)"
      ],
      "metadata": {
        "id": "5r4PMSvQB9Kd"
      },
      "id": "5r4PMSvQB9Kd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Se extraen las palabras clave de cada articulo "
      ],
      "metadata": {
        "id": "TCK8z_ouCERx"
      },
      "id": "TCK8z_ouCERx"
    },
    {
      "cell_type": "code",
      "source": [
        "## Se extrae la información de las palabras clave por cada uno de los artículos para estructurarlo en una tabla\n",
        "result_keywords_list = list()\n",
        "for i,row in df_total.iterrows():\n",
        "    if row['keywords'] and isinstance(row['keywords'], str):\n",
        "        for keyword in row['keywords'].split(','):\n",
        "            result_keywords_list.append({'dc:identifier':row['dc:identifier'],\n",
        "                                         'prism:coverDate': row['prism:coverDate'],\n",
        "                                         'keyword': keyword.strip().lower()})\n",
        "df_keywords = pd.DataFrame(result_keywords_list)"
      ],
      "metadata": {
        "id": "R7bsvU_fCNnK"
      },
      "id": "R7bsvU_fCNnK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Almacenamiento de la información de las palabras clave en formato csv\n",
        "df_keywords.to_csv('./data/elsevier_scopus_salud_keywords.csv', index=False)"
      ],
      "metadata": {
        "id": "gPP0FqlRCVLy"
      },
      "id": "gPP0FqlRCVLy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creación del repositorio en SQLLite\n",
        "Se crea la base de datos la cual se popula utilizando el IDE que ofrece Superset"
      ],
      "metadata": {
        "id": "CFo4AVF-Cf3W"
      },
      "id": "CFo4AVF-Cf3W"
    },
    {
      "cell_type": "code",
      "source": [
        "!C:\\sqlite\\sqlite3.exe ./data/csv_database.db"
      ],
      "metadata": {
        "id": "yT2lnhgWCuhA"
      },
      "id": "yT2lnhgWCuhA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Extracción y Procesamiento - ElSevier API.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}